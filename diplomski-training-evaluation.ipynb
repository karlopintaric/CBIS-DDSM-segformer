{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -Uqq lightning segmentation-models-pytorch","metadata":{"execution":{"iopub.status.busy":"2023-08-26T20:38:56.209246Z","iopub.execute_input":"2023-08-26T20:38:56.209871Z","iopub.status.idle":"2023-08-26T20:39:21.318589Z","shell.execute_reply.started":"2023-08-26T20:38:56.209832Z","shell.execute_reply":"2023-08-26T20:39:21.317086Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport torch\nfrom glob import glob\nimport lightning.pytorch as pl\nfrom torch.utils.data import DataLoader, Dataset\nfrom sklearn.model_selection import train_test_split\nfrom PIL import Image\nimport albumentations as A\nfrom transformers import SegformerForSemanticSegmentation, SegformerImageProcessor\nfrom albumentations.pytorch.transforms import ToTensorV2\nimport matplotlib.pyplot as plt\nfrom torch import nn\nimport segmentation_models_pytorch as smp\nimport cv2\nimport torch.nn.functional as F\nfrom sklearn.model_selection import StratifiedGroupKFold\nfrom tqdm.notebook import tqdm\n\nfrom lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping, GradientAccumulationScheduler, LearningRateMonitor","metadata":{"execution":{"iopub.status.busy":"2023-08-26T20:39:21.321320Z","iopub.execute_input":"2023-08-26T20:39:21.322373Z","iopub.status.idle":"2023-08-26T20:39:40.617135Z","shell.execute_reply.started":"2023-08-26T20:39:21.322332Z","shell.execute_reply":"2023-08-26T20:39:40.616149Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"SEED = 123\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed(SEED)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\nnp.random.seed(SEED)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T20:39:40.618735Z","iopub.execute_input":"2023-08-26T20:39:40.619144Z","iopub.status.idle":"2023-08-26T20:39:40.631312Z","shell.execute_reply.started":"2023-08-26T20:39:40.619110Z","shell.execute_reply":"2023-08-26T20:39:40.630146Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def get_cancer_status(images):\n    masks = [image.replace(\"FULL\", \"MASK\") for image in images]\n    cancer_status = np.array([np.isin(2, Image.open(mask)).any() for mask in masks])\n    return cancer_status.astype(int)\n\ndef splitter(images, splits, random_state=0):\n    images = sorted(images)\n    \n    patients = np.array([str(x).split(\"/\")[-2] for x in images]) \n    cancers = get_cancer_status(images)\n    \n    gkf = StratifiedGroupKFold(n_splits=splits, shuffle=True, random_state=random_state)\n    return list(gkf.split(X=images, y=cancers, groups=patients))","metadata":{"execution":{"iopub.status.busy":"2023-08-26T20:39:40.634664Z","iopub.execute_input":"2023-08-26T20:39:40.635091Z","iopub.status.idle":"2023-08-26T20:39:40.643454Z","shell.execute_reply.started":"2023-08-26T20:39:40.635059Z","shell.execute_reply":"2023-08-26T20:39:40.642457Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def diff_lr(model, lr, weight_decay=0, diff=100, no_decay=[\"bias\", \"norm\"], body=[\"embeddings\", \"encoder\"]):\n    \n    head_params = [(n,p) for n, p in model.named_parameters() if not any(body_param in n for body_param in body)]\n    body_params = [(n,p) for n, p in model.named_parameters() if any(body_param in n for body_param in body)]\n    \n    #head lr\n    optimizer_grouped_parameters = [\n        {\n            \"params\": [p for n, p in head_params if not any(nd in n for nd in no_decay)],\n            \"weight_decay\": weight_decay,\n            \"lr\": lr,\n        },\n        {\n            \"params\": [p for n, p in head_params if any(nd in n for nd in no_decay)],\n            \"weight_decay\": 0.0,\n            \"lr\": lr,\n        },\n    ]\n\n    # body lr\n    optimizer_grouped_parameters += [\n        {\n            \"params\": [p for n, p in body_params if not any(nd in n for nd in no_decay)],\n            \"weight_decay\": weight_decay,\n            \"lr\": lr/diff,\n        },\n        {\n            \"params\": [p for n, p in body_params if any(nd in n for nd in no_decay)],\n            \"weight_decay\": 0.0,\n            \"lr\": lr/diff,\n        },\n    ]\n\n    return optimizer_grouped_parameters\n","metadata":{"execution":{"iopub.status.busy":"2023-08-26T20:39:40.644882Z","iopub.execute_input":"2023-08-26T20:39:40.645928Z","iopub.status.idle":"2023-08-26T20:39:40.656854Z","shell.execute_reply.started":"2023-08-26T20:39:40.645896Z","shell.execute_reply":"2023-08-26T20:39:40.656138Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class MammoDataset(Dataset):\n    def __init__(self, images, transforms=None):\n        self.images = images\n        self.transforms = transforms\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        img_path = self.images[idx]\n        mask_path = self.images[idx].replace(\"FULL\", \"MASK\")\n        image = Image.open(img_path).convert(\"RGB\")\n        mask = Image.open(mask_path)\n\n        if self.transforms:\n            transformed = self.transforms(image=np.array(image), mask=np.array(mask).astype(np.uint8))\n            image = transformed['image']\n            mask = transformed['mask']\n\n        #Use the feature extractor\n        feature_extractor = SegformerImageProcessor(do_reduce_labels=False, \n                                                    do_resize=False,\n                                                    do_normalize=True,)\n        encoded_inputs = feature_extractor(images=image, segmentation_maps=mask, return_tensors=\"pt\")\n\n        for k,_ in encoded_inputs.items():\n            encoded_inputs[k].squeeze_()\n\n        return encoded_inputs","metadata":{"execution":{"iopub.status.busy":"2023-08-26T20:39:40.658072Z","iopub.execute_input":"2023-08-26T20:39:40.658846Z","iopub.status.idle":"2023-08-26T20:39:40.671552Z","shell.execute_reply.started":"2023-08-26T20:39:40.658803Z","shell.execute_reply":"2023-08-26T20:39:40.670991Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class MammoDataModule(pl.LightningDataModule):\n    def __init__(self, \n                 train_image_dir: str, test_image_dir: str, \n                 batch_size: int = 8, \n                 train_transforms=None, val_transforms=None,\n                 splits = 4, fold = 0, num_workers=4, random_state=123):\n        super().__init__()\n        self.train_image_dir = train_image_dir\n        self.test_image_dir = test_image_dir\n        self.batch_size = batch_size\n        self.train_transforms = train_transforms\n        self.val_transforms = val_transforms\n        self.num_workers = num_workers\n        self.fold = fold\n        self.splits = splits\n        self.random_state = random_state\n\n    def setup(self, stage):\n        all_images = np.array(self._get_all_images(self.train_image_dir))\n        splits = splitter(all_images, self.splits, self.random_state)\n        train_idx, val_idx = splits[self.fold]\n        train_images, val_images = all_images[train_idx], all_images[val_idx]\n\n        self.train_dataset = MammoDataset(train_images, self.train_transforms)\n        self.val_dataset = MammoDataset(val_images, self.val_transforms)\n\n        test_images = self._get_all_images(self.test_image_dir)\n        self.test_dataset = MammoDataset(test_images, self.val_transforms)\n\n    def train_dataloader(self):\n        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=self.num_workers, pin_memory=True)\n\n    def val_dataloader(self):\n        return DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers, pin_memory=True)\n    \n    def test_dataloader(self):\n        return DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers, pin_memory=True)\n    \n    def _get_all_images(self, image_dir: str):\n        return glob(f\"{image_dir}/**/*_FULL.png\", recursive=True)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T20:39:40.672939Z","iopub.execute_input":"2023-08-26T20:39:40.673848Z","iopub.status.idle":"2023-08-26T20:39:40.687638Z","shell.execute_reply.started":"2023-08-26T20:39:40.673810Z","shell.execute_reply":"2023-08-26T20:39:40.686613Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class SegformerFinetuner(pl.LightningModule):\n    \n    def __init__(self, model: str, loss: nn.Module, id2label: dict, lr: float, wd: float):\n        super().__init__()\n        \n        self.id2label = id2label\n        self.num_classes = len(id2label.keys())\n        self.label2id = {v:k for k,v in self.id2label.items()}\n        \n        self.model = SegformerForSemanticSegmentation.from_pretrained(\n            model, \n            return_dict=False, \n            num_labels=self.num_classes,\n            id2label=self.id2label,\n            label2id=self.label2id,\n        )\n        self.criterion = loss\n        self.lr = lr\n        self.weight_decay = wd\n        \n        self.metrics = {}\n        self.validation_step_outputs = []\n        self.validation_step_labels = []\n        \n    def forward(self, images):\n        outputs = self.model(pixel_values=images)\n\n        upsampled_logits = self._upsample_logits(outputs[0], images)\n        \n        return(upsampled_logits)\n    \n    def training_step(self, batch, batch_nb):\n        \n        loss, _, _ = self._calculate_loss(batch)\n        \n        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True)\n        \n        return loss\n    \n    def validation_step(self, batch, batch_nb):\n        \n        loss, upsampled_logits, masks = self._calculate_loss(batch)\n        \n        predicted = upsampled_logits.argmax(dim=1)\n        \n        self.validation_step_outputs.append(predicted.detach().cpu().long())\n        self.validation_step_labels.append(masks.detach().cpu())\n        \n        self.log(\"val_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n        \n        return loss\n    \n    def on_validation_epoch_end(self):\n        \n        all_preds = torch.cat(self.validation_step_outputs)\n        all_labels = torch.cat(self.validation_step_labels)\n        \n        tp, fp, fn, tn = smp.metrics.get_stats(all_preds, all_labels, mode='multiclass', num_classes=3)\n        iou_score = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"macro\")\n        accuracy = smp.metrics.accuracy(tp, fp, fn, tn, reduction=\"macro\")\n        f1_score = smp.metrics.f1_score(tp, fp, fn, tn, reduction=\"macro\")\n        \n        metrics = {\"val_mean_iou\":iou_score, \"val_mean_accuracy\":accuracy, \"val_mean_f1_score\": f1_score}\n        self.log_dict(metrics, prog_bar=True)\n        self.metrics = metrics\n        \n        self.validation_step_outputs.clear()\n        self.validation_step_labels.clear()\n    \n    \n    def configure_optimizers(self):\n        grouped_params = diff_lr(self.model, lr = self.lr, weight_decay = self.weight_decay)\n        optimizer = torch.optim.AdamW(grouped_params)\n        return {\n            \"optimizer\": optimizer,\n            \"lr_scheduler\": {\n                \"scheduler\": torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3,factor=0.1, min_lr=1e-8, threshold=0.01, verbose=True),\n                \"monitor\": \"val_loss\"\n            },\n        }\n    \n    def _upsample_logits(self, logits, masks):\n        return nn.functional.interpolate(\n            logits, \n            size=masks.shape[-2:], \n            mode=\"bilinear\", \n            align_corners=False\n        )\n    \n    def _calculate_loss(self, batch):\n        images, masks = batch['pixel_values'], batch['labels']\n        \n        outputs = self.model(pixel_values=images, labels=masks)\n        \n        logits = outputs[1]\n        \n        upsampled_logits = self._upsample_logits(logits, masks)\n\n        loss = self.criterion(upsampled_logits, masks)\n\n        return loss, upsampled_logits, masks\n","metadata":{"execution":{"iopub.status.busy":"2023-08-26T20:39:40.689437Z","iopub.execute_input":"2023-08-26T20:39:40.689761Z","iopub.status.idle":"2023-08-26T20:39:40.712898Z","shell.execute_reply.started":"2023-08-26T20:39:40.689738Z","shell.execute_reply":"2023-08-26T20:39:40.712057Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"train_transforms = A.Compose([\n    A.HorizontalFlip(p=0.5),\n    A.VerticalFlip(p=0.5),\n    #A.RandomRotate90(p=0.5),\n    #A.Transpose(p=0.5),\n    A.RandomBrightnessContrast(p=0.5, brightness_limit=0.05, contrast_limit=0.05),\n])\n","metadata":{"execution":{"iopub.status.busy":"2023-08-26T20:39:40.715332Z","iopub.execute_input":"2023-08-26T20:39:40.716054Z","iopub.status.idle":"2023-08-26T20:39:40.729971Z","shell.execute_reply.started":"2023-08-26T20:39:40.716020Z","shell.execute_reply":"2023-08-26T20:39:40.728951Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"TRAIN_DIR = \"/kaggle/input/diplomski-datapreprocessing-512xalleq/data/train/processed_512x_alleq\"\nTEST_DIR = \"/kaggle/input/diplomski-datapreprocessing-512xalleq/data/test/processed_512x_alleq\"\n\nid2label = {0:\"BACKGROUND\", 1:\"BENIGN\", 2:\"MALIGNANT\"}\nNUM_FOLDS = 4\n\nall_metrics = {\"val_mean_iou\": [], \"val_mean_accuracy\": [], \"val_mean_f1_score\": []}","metadata":{"execution":{"iopub.status.busy":"2023-08-26T20:39:40.733721Z","iopub.execute_input":"2023-08-26T20:39:40.734093Z","iopub.status.idle":"2023-08-26T20:39:40.741078Z","shell.execute_reply.started":"2023-08-26T20:39:40.734063Z","shell.execute_reply":"2023-08-26T20:39:40.739835Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"class ComboLoss(nn.Module):\n    \n    def __init__(self, alpha, w1=0.5, w2=0.5, smooth=0):\n        super().__init__()\n        self.w1 = w1\n        self.w2 = w2\n        self.multi_criterion = smp.losses.DiceLoss(mode=\"multiclass\", smooth=smooth)\n        self.binary_criterion = smp.losses.TverskyLoss(mode=\"binary\", alpha = alpha, beta = 1 - alpha)\n    \n    def forward(self, output, target):\n        multi_loss = self.multi_criterion(output, target)\n        \n        binary_output = nn.functional.softmax(output, dim=1)[:, 1:, :, :].sum(dim=1, keepdim=True)\n        binary_target = (target != 0).long()\n        binary_loss = self.binary_criterion(binary_output, binary_target)\n    \n        return self.w1 * multi_loss + self.w2 * binary_loss","metadata":{"execution":{"iopub.status.busy":"2023-08-26T20:39:40.742287Z","iopub.execute_input":"2023-08-26T20:39:40.742978Z","iopub.status.idle":"2023-08-26T20:39:40.755608Z","shell.execute_reply.started":"2023-08-26T20:39:40.742946Z","shell.execute_reply":"2023-08-26T20:39:40.754444Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"MODEL_FOLDER = \"/kaggle/input/diplomski-training/models\"","metadata":{"execution":{"iopub.status.busy":"2023-08-26T20:39:40.757221Z","iopub.execute_input":"2023-08-26T20:39:40.757628Z","iopub.status.idle":"2023-08-26T20:39:40.766063Z","shell.execute_reply.started":"2023-08-26T20:39:40.757597Z","shell.execute_reply":"2023-08-26T20:39:40.765107Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"dm = MammoDataModule(\n        TRAIN_DIR, \n        TEST_DIR, \n        batch_size=32,\n        train_transforms=train_transforms,\n        num_workers=2,\n        splits=4,\n        fold=0,\n        random_state=123)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T20:41:34.722136Z","iopub.execute_input":"2023-08-26T20:41:34.722597Z","iopub.status.idle":"2023-08-26T20:41:34.733011Z","shell.execute_reply.started":"2023-08-26T20:41:34.722562Z","shell.execute_reply":"2023-08-26T20:41:34.731958Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Initialize a tensor to store the sum of all predictions\nsum_preds = None\nlast_masks = None\n\ndm.setup(stage=\"test\")\nfor k in range(NUM_FOLDS):\n   \n    MODEL_NAME = f\"segformer-fold-{k}\"\n    segformer_finetuner = SegformerFinetuner(\n    f\"./models/{MODEL_NAME}\",\n    nn.CrossEntropyLoss(),\n    id2label,\n    lr=1e-3,\n    wd=0)\n       \n    fold_preds = []\n    fold_masks = []\n    \n    segformer_finetuner.eval()\n    \n    with torch.no_grad():\n        for batch in tqdm(dm.test_dataloader()):\n            images, masks = batch['pixel_values'], batch['labels']\n            upsampled_logits = segformer_finetuner(images)\n            \n            probs = torch.nn.functional.softmax(upsampled_logits, dim=1)\n            fold_preds.append(probs.detach().cpu())\n            fold_masks.append(masks.detach().cpu())\n    \n    # Combine the predictions and masks of the fold\n    fold_preds = torch.cat(fold_preds, dim=0)\n    fold_masks = torch.cat(fold_masks, dim=0)\n\n    # Add the fold predictions to the sum\n    if sum_preds is None:\n        sum_preds = fold_preds\n    else:\n        sum_preds += fold_preds\n\n    # Save the masks from the last fold\n\n# Average the predictions by dividing the sum by the number of folds\navg_preds = sum_preds / NUM_FOLDS\n\n# Get the predicted classes\npred_classes = torch.argmax(avg_preds, dim=1)\n\ntp, fp, fn, tn = smp.metrics.get_stats(pred_classes, fold_masks, mode='multiclass', num_classes=3)\niou_score = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"macro\")\naccuracy = smp.metrics.accuracy(tp, fp, fn, tn, reduction=\"macro\")\nf1_score = smp.metrics.f1_score(tp, fp, fn, tn, reduction=\"macro\")\n\nprint(f'Dice Score: {f1_score}\\n'\n      f'IoU Score: {iou_score}\\n'\n      f'Accuracy: {accuracy}')","metadata":{"execution":{"iopub.status.busy":"2023-08-26T20:39:41.825701Z","iopub.status.idle":"2023-08-26T20:39:41.826409Z","shell.execute_reply.started":"2023-08-26T20:39:41.826166Z","shell.execute_reply":"2023-08-26T20:39:41.826188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}